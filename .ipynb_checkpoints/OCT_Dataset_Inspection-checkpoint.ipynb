{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OCT Dataset Inspection Notebook\n",
        "\n",
        "**Purpose:** Quickly inspect and summarise a retinal OCT dataset for classification tasks (e.g., NORMAL / CNV / DME / DRUSEN).\n",
        "\n",
        "**What this notebook does:**\n",
        "- Detect class folders and count images\n",
        "- Build a metadata table (path, class, width, height, file size)\n",
        "- Plot class balance and image size distribution (matplotlib only)\n",
        "- Create a simple montage image preview (single-plot)\n",
        "- Export a `labels.csv` ready for PyTorch training (split by patient if available)\n",
        "\n",
        "**Instructions:**\n",
        "1. Set `DATA_ROOT` below to your dataset path (parent folder containing class subfolders).\n",
        "2. (Optional) Adjust `CLASS_DIRS` if your class folders differ.\n",
        "3. Run each cell top-to-bottom.\n",
        "\n",
        "> Note: This notebook intentionally avoids seaborn and subplots. Each figure is a single-plot matplotlib figure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os, sys, csv, math, random, hashlib\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === CONFIG ===\n",
        "DATA_ROOT = \"/path/to/OCT_Dataset\"  # <-- CHANGE THIS to your dataset root\n",
        "# If None, class directories will be auto-detected as immediate subfolders of DATA_ROOT.\n",
        "CLASS_DIRS = None  # e.g., [\"CNV\", \"DME\", \"DRUSEN\", \"NORMAL\"]\n",
        "\n",
        "# Allowed image extensions\n",
        "IMG_EXTS = {\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\", \".bmp\"}\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "RNG_SEED = 42\n",
        "random.seed(RNG_SEED)\n",
        "np.random.seed(RNG_SEED)\n",
        "\n",
        "DATA_ROOT = Path(DATA_ROOT)\n",
        "assert DATA_ROOT.exists(), f\"DATA_ROOT not found: {DATA_ROOT}\"\n",
        "\n",
        "if CLASS_DIRS is None:\n",
        "    CLASS_DIRS = [p.name for p in DATA_ROOT.iterdir() if p.is_dir()]\n",
        "CLASS_DIRS = sorted(CLASS_DIRS)\n",
        "print(\"Detected classes:\", CLASS_DIRS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Scan files and build a metadata table\n",
        "rows = []\n",
        "for cls in CLASS_DIRS:\n",
        "    cdir = DATA_ROOT / cls\n",
        "    if not cdir.exists():\n",
        "        print(f\"Warning: class folder missing: {cdir}\")\n",
        "        continue\n",
        "    for root, _, files in os.walk(cdir):\n",
        "        for fn in files:\n",
        "            ext = os.path.splitext(fn)[1].lower()\n",
        "            if ext in IMG_EXTS:\n",
        "                fp = Path(root) / fn\n",
        "                try:\n",
        "                    with Image.open(fp) as im:\n",
        "                        w, h = im.size\n",
        "                except Exception as e:\n",
        "                    print(f\"[SKIP] {fp}: {e}\")\n",
        "                    continue\n",
        "                size_bytes = fp.stat().st_size\n",
        "                rows.append({\n",
        "                    \"path\": str(fp),\n",
        "                    \"label_name\": cls,\n",
        "                    \"width\": w,\n",
        "                    \"height\": h,\n",
        "                    \"filesize\": size_bytes,\n",
        "                })\n",
        "meta = pd.DataFrame(rows)\n",
        "assert len(meta) > 0, \"No images found. Check DATA_ROOT and CLASS_DIRS.\"\n",
        "print(\"Total images:\", len(meta))\n",
        "meta.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Class counts\n",
        "class_counts = meta['label_name'].value_counts().sort_index()\n",
        "print(class_counts)\n",
        "\n",
        "# Plot class balance (single plot)\n",
        "plt.figure()\n",
        "class_counts.plot(kind='bar')\n",
        "plt.title('Class Counts')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Images')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Image area distribution\n",
        "areas = (meta['width'] * meta['height']).astype(int)\n",
        "plt.figure()\n",
        "plt.hist(areas, bins=50)\n",
        "plt.title('Image Area Distribution (pixels)')\n",
        "plt.xlabel('Area (WÃ—H)')\n",
        "plt.ylabel('Count')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"Mean area:\", int(areas.mean()))\n",
        "print(\"Median area:\", int(areas.median()))\n",
        "print(\"Min/Max area:\", int(areas.min()), int(areas.max()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build a single-image montage (no subplots): stitch a grid using PIL, then show once.\n",
        "def build_montage(paths, grid=(4, 6), thumb=(160, 160)):\n",
        "    cols, rows = grid[1], grid[0]\n",
        "    W, H = thumb\n",
        "    canvas = Image.new('L', (cols*W, rows*H), color=0)\n",
        "    for i, p in enumerate(paths[:rows*cols]):\n",
        "        try:\n",
        "            with Image.open(p).convert('L') as im:\n",
        "                im = im.resize((W, H))\n",
        "                x = (i % cols) * W\n",
        "                y = (i // cols) * H\n",
        "                canvas.paste(im, (x, y))\n",
        "        except Exception:\n",
        "            pass\n",
        "    return canvas\n",
        "\n",
        "sample_paths = []\n",
        "per_class = 6\n",
        "for cls in CLASS_DIRS:\n",
        "    paths = meta[meta['label_name']==cls]['path'].tolist()\n",
        "    random.shuffle(paths)\n",
        "    sample_paths.extend(paths[:per_class])\n",
        "\n",
        "mont = build_montage(sample_paths, grid=(4, 6), thumb=(160, 160))\n",
        "plt.figure()\n",
        "plt.imshow(mont, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.title('Sample Montage')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Optional: naive duplicate detection via file hash on a subset\n",
        "def file_hash(path, block_size=1<<20):\n",
        "    h = hashlib.md5()\n",
        "    with open(path, 'rb') as f:\n",
        "        while True:\n",
        "            b = f.read(block_size)\n",
        "            if not b:\n",
        "                break\n",
        "            h.update(b)\n",
        "    return h.hexdigest()\n",
        "\n",
        "subset = meta.sample(min(len(meta), 2000), random_state=RNG_SEED).copy()\n",
        "subset['md5'] = subset['path'].apply(file_hash)\n",
        "dups = subset[subset.duplicated('md5', keep=False)].sort_values('md5')\n",
        "print(f\"Checked {len(subset)} files; potential duplicates found:\", dups['md5'].nunique())\n",
        "dups.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Export labels.csv for training (image-level). You can later aggregate per patient.\n",
        "label_to_id = {cls:i for i, cls in enumerate(CLASS_DIRS)}\n",
        "meta['label'] = meta['label_name'].map(label_to_id)\n",
        "\n",
        "# Heuristic patient_id from path (customise for your dataset)\n",
        "from pathlib import Path\n",
        "def infer_patient_id(p):\n",
        "    p = Path(p)\n",
        "    parent = p.parent.name\n",
        "    stem_digits = ''.join([c for c in p.stem if c.isdigit()]) or 'na'\n",
        "    return f\"{parent}_{stem_digits}\"\n",
        "\n",
        "meta['patient_id'] = meta['path'].apply(infer_patient_id)\n",
        "\n",
        "labels = meta[['patient_id','path','label','label_name']].copy()\n",
        "labels.to_csv('labels.csv', index=False)\n",
        "print('Wrote labels.csv with', len(labels), 'rows')\n",
        "labels.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "- Verify `labels.csv` and adjust `patient_id` parsing to your dataset naming.\n",
        "- Create **patient-level** splits (train/val/test) to avoid leakage.\n",
        "- Plug `labels.csv` into your PyTorch scaffold (`experiments/exp001_baseline.yaml`).\n",
        "- Start with a small subset to prove the pipeline, then scale up."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}